# 提示词验证系统使用指南

## 系统功能概述

"提示词验证"系统已成功集成到NxLink管理工具中，作为一级菜单项显示在左侧菜单栏。该系统支持：

1. **LLM厂商配置** - 配置多个LLM提供商和模型
2. **提示词管理** - 创建和管理提示词模板
3. **批量测试** - 同时测试多个提示词和模型组合
4. **结果对比** - 查看和对比不同模型的输出效果

## 主要功能点实现

### 1. LLM厂商配置
- 支持11个主流LLM厂商和40+个模型：
  - **国际厂商**：Mistral AI、OpenAI、Azure OpenAI、Anthropic、Google Gemini、Groq、DeepSeek、Cerebras
  - **国内厂商**：百度文心、阿里通义
  - **自定义LLM**：支持本地部署和第三方平台托管的模型
- 支持厂商特定配置（如Azure OpenAI的Endpoint和Deployment Name）
- 可配置API Key和选择具体模型
- 支持编辑和删除配置

### 2. 提示词管理
- 创建带变量的提示词模板（使用{{变量名}}语法）
- 支持提示词的复制、编辑和删除
- 自动识别提示词中的变量

### 3. 批量测试
- 选择多个提示词和多个模型进行交叉测试
- 设置测试参数（运行次数、Temperature、Max Tokens）
- **真实API调用**：支持各厂商的实际API接口调用
- 实时显示测试进度
- 支持中止测试
- 自动处理不同厂商的API格式差异

### 4. 测试结果
- 查看历史测试记录
- 按提示词分组显示不同模型的输出
- 显示响应时间和Token使用情况
- 支持复制输出内容

## 访问方式

1. 启动开发服务器：`npm run dev`
2. 访问 http://localhost:5173
3. 在左侧菜单找到"提示词验证"（图标为实验烧瓶）

## 数据存储

当前使用localStorage存储数据，包括：
- `llm_providers` - LLM配置信息
- `prompts` - 提示词列表
- `test_runs` - 测试运行记录

## 重要更新

### 已完成的功能升级

1. **✅ 真实LLM API调用**：已实现对11个主流LLM厂商的真实API调用
2. **✅ 多厂商支持**：支持40+个不同的LLM模型
3. **✅ 自动格式处理**：自动处理不同厂商的API请求和响应格式
4. **✅ 厂商特定配置**：支持Azure OpenAI、Custom LLM等特殊配置要求

### 待完善功能

1. 添加数据导入导出功能
2. 增加更详细的测试结果分析
3. 支持更多的测试参数配置
4. 添加成本计算和使用情况统计

## 配置指南

详细的LLM厂商配置说明请参考：[LLM厂商配置指南](./llm-configuration-guide.md) 